{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf3e400",
   "metadata": {},
   "source": [
    "## COMP8210 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ceaaae",
   "metadata": {},
   "source": [
    "# Task 1: Data Curation\n",
    "Data was cleaned to make sure it is valid in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1e9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "file = open(\"10000 tweets 1.json\", 'r')\n",
    "file_contents = file.read()\n",
    "#save the lines in a list\n",
    "contents_list = file_contents.splitlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfdb2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the white space\n",
    "contents_list = [x.strip() for x in contents_list if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a6657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/* 10000 Tweets */',\n",
       " '/* 1 */',\n",
       " '{',\n",
       " '\"_id\" : ObjectId(\"abe415aa5e7133a4a61c0d8317875\"),',\n",
       " '\"id\" : \"149715690143449899009\",',\n",
       " '\"objectType\" : \"activity\",',\n",
       " '\"actor\" : {',\n",
       " '\"objectType\" : \"person\",',\n",
       " '\"id\" : \"10243188921458\",',\n",
       " '\"link\" : \"http://www.twitter.com/losebabyweight1\",']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the content\n",
    "contents_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c8db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary words\n",
    "contents_list.remove(\"/* 10000 Tweets */\")\n",
    "contents_list.remove(\"/* 1 */\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b34f74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{',\n",
       " '\"_id\" : ObjectId(\"abe415aa5e7133a4a61c0d8317875\"),',\n",
       " '\"id\" : \"149715690143449899009\",',\n",
       " '\"objectType\" : \"activity\",',\n",
       " '\"actor\" : {',\n",
       " '\"objectType\" : \"person\",',\n",
       " '\"id\" : \"10243188921458\",',\n",
       " '\"link\" : \"http://www.twitter.com/losebabyweight1\",',\n",
       " '\"displayName\" : \"losebabyweight\",',\n",
       " '\"postedTime\" : \"2010-09-09T22:40:10.000Z\",']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the content\n",
    "contents_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d817df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace lines started with \"/* \" with comma to separate each tweets\n",
    "for i, item in enumerate(contents_list):\n",
    "    if \"/* \" in item:\n",
    "        contents_list[i] = \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d77d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ObjectId items which are auto-generated ids in MongoDB and needed to be removed to prevent errors\n",
    "for i, item in enumerate(contents_list):\n",
    "    if \"ObjectId\" in item:\n",
    "        contents_list[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1826f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace items which store data as 'NumberLong(numbers)' with pure integers by removing the characters \n",
    "for i, item in enumerate(contents_list):\n",
    "    if \"NumberLong\" in item:\n",
    "        text = item.replace(\"NumberLong(\", \"\")\n",
    "        contents_list[i] = text.replace(\")\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8977bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the lines into a string\n",
    "data = ''\n",
    "for x in contents_list:\n",
    "    data += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b85a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add square brackets to turn it into a list of dictionaries \n",
    "data = \"[\" + data + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8caeaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68446ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write into file\n",
    "with open('cleaned_10000_tweets.json', 'w+',encoding='utf-8-sig') as f:\n",
    "        f.write(data)\n",
    "# if want to view as a list of dictionaries in Visual Studio Code, \n",
    "# use cmd A to select all, then press cmd K then cmd F to auto indent the codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707313",
   "metadata": {},
   "source": [
    "# Task 2: Graph Data Model\n",
    " Cypher codes are used to create the Graph Data Model for Tweets in Twitter in Neo4j.\n",
    "\n",
    "The final graph data model is as below:\n",
    "``CALL db.schema.visualization``\n",
    "![graph data model](https://i.im.ge/2022/09/21/1DpuaL.graph-data-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3970fad5",
   "metadata": {},
   "source": [
    "### Connect to Neo4j and using Neo4j Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b42e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j-driver in /opt/anaconda3/lib/python3.8/site-packages (5.0.1)\r\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.8/site-packages (from neo4j-driver) (2021.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install the neo4j-driver package\n",
    "!pip install neo4j-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d057ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1600beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri=\"bolt://localhost:7687\", user=\"neo4j\", pwd=\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c95f57c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"CREATE OR REPLACE DATABASE Tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f486561",
   "metadata": {},
   "source": [
    "### Create Constraints\n",
    "The below constraints are created to ensure uniqueness of the data created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78be6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_constraint_query = '''\n",
    "CREATE CONSTRAINT ON (t:Tweet) ASSERT t.tweetID IS UNIQUE;\n",
    "CREATE CONSTRAINT ON (u:User) ASSERT u.userID IS UNIQUE;\n",
    "CREATE CONSTRAINT ON (h:Hashtag) ASSERT h.tag IS UNIQUE;\n",
    "CREATE CONSTRAINT ON (l:Link) ASSERT l.url IS UNIQUE;\n",
    "CREATE CONSTRAINT ON (s:Source) ASSERT s.source IS UNIQUE\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_constraint_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb54a1",
   "metadata": {},
   "source": [
    "### Create Tweet node\n",
    "The Tweet node contains:  \n",
    "**tweetID**: id of the tweet   \n",
    "**text**: content of the tweet  \n",
    "**action**: obtained through \"verb\" (post = original; share = retweet)   \n",
    "**link**: the link to the tweet   \n",
    "**postedTime**: the posted time of the tweet   \n",
    "**datePublished**: it is extracted from postedTime and used later in Q2 of Part 3 query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6659a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tweet_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.id AS tweetID,\n",
    "datetime({ epochMillis: apoc.date.parse(value.postedTime, \"ms\",\n",
    "\"yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'\")}) AS postedTime,\n",
    "value.text AS text,\n",
    "value.verb AS verb,\n",
    "value.link AS link\n",
    "MERGE (t:Tweet{tweetID:tweetID}) \n",
    "ON CREATE SET\n",
    "t.postedTime = postedTime,\n",
    "t.datePublished = date(postedTime),\n",
    "t.text = text,\n",
    "t.action = verb,\n",
    "t.link = link',\n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_tweet_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ad762",
   "metadata": {},
   "source": [
    "### Create Retweeted Tweets and **\\[Tweet RETWEETS Tweet\\]** relationship\n",
    "\n",
    "Firstly, retweeted tweets are identified from the json file through the user's action stored in (\"verb\": \"share\"). Then, the information of the original retweeted tweets are extracted from **\"object\"** and stored in the Tweet Node.  \n",
    "  \n",
    "The Tweet node contains:  \n",
    "**tweetID**: id of the retweeted tweet   \n",
    "**text**: content of the retweeted tweet  \n",
    "**action**: it is obtained from \"verb\" in json file and is \"post\"^          \n",
    "**link**: the link to the retweeted tweet  \n",
    "**postedTime**: the post time of the retweeted tweet   \n",
    "**datePublished**: it is extracted from postedTime and used later in Q2 of Part 3 query.  \n",
    "*^Note: From json file, for retweeted tweets, the action is \"post\".   \n",
    "For instance, User1 shared Tweet1 which was a retweet of Tweet2 posted by User2. Therefore, the action of tweet posted by User1 is \"share\" and the action of tweet posted by User2 is \"post\".*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f49d1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_retweet_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.id AS tweetID,\n",
    "value.object.id AS retweetID,\n",
    "datetime({epochMillis: apoc.date.parse(value.object.postedTime, \"ms\", \n",
    "\"yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'\")}) AS postedTime,\n",
    "Date(datetime({epochMillis: apoc.date.parse(value.object.postedTime, \"ms\", \n",
    "\"yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'\")})) AS datePublished, \n",
    "value.object.text AS text,\n",
    "value.object.verb AS verb,\n",
    "value.object.link AS link\n",
    "MATCH (t:Tweet{tweetID:tweetID})\n",
    "WHERE t.action = \"share\"\n",
    "MERGE (rt:Tweet{tweetID:retweetID, postedTime:postedTime, datePublished :datePublished , text:text, action:verb, link:link}) \n",
    "MERGE (rt)<-[:RETWEETS]-(t)',\n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e68a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_retweet_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d2d5d",
   "metadata": {},
   "source": [
    "### Create Link node and **\\[Tweet CONTAINS Link\\]** relationship\n",
    "The Link node contains:  \n",
    "**url**: the link(s) embedded in the tweet, NOT the link to the tweet itself.   \n",
    "The url is extracted from \"expanded_url\" in \"twitter_entities\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cc4e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_link_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.twitter_entities AS e, \n",
    "value.id AS tweetID\n",
    "MATCH(t:Tweet{tweetID:tweetID}) \n",
    "FOREACH (u IN e.urls |\n",
    "MERGE (url:Link {url:u.expanded_url})\n",
    "MERGE (url)<-[:CONTAINS]-(t))', \n",
    "{batchSize:500}) YIELD * ;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfcbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_link_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a81e6",
   "metadata": {},
   "source": [
    "### Create Link node and **\\[Tweet CONTAINS Link\\]** relationship for *Retweeted Tweets*\n",
    "*Note: Retweeted tweets data is stored in \"object\", therefore, it is created separately to establish the relationship for retweeted tweets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rt_link_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.object.twitter_entities AS e, \n",
    "value.object.id AS retweetID\n",
    "MATCH(t:Tweet{tweetID:retweetID}) \n",
    "FOREACH (u IN e.urls |\n",
    "MERGE (url:Link {url:u.expanded_url})\n",
    "MERGE (url)<-[:CONTAINS]-(t))', \n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ba3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_rt_link_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1c645",
   "metadata": {},
   "source": [
    "### Create Source node and **\\[Tweet USING Source\\]** relationship\n",
    "Source node contains:  \n",
    "**source**: the app or site to post or share a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_source_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', 'WITH \n",
    "value.generator.displayName AS source, value.id AS tweetID\n",
    "MATCH(t:Tweet{tweetID:tweetID}) \n",
    "MERGE (s:Source{source:source}) MERGE (t)-[:USING]->(s)', \n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c679633",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_source_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935bdbc",
   "metadata": {},
   "source": [
    "### Create Source node and **\\[Tweet USING Source\\]** relationship for *Retweeted Tweets*\n",
    "*Note: Retweeted tweets data is stored in \"object\", therefore, it is created separately to establish the relationship for retweeted tweets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rt_source_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', 'WITH \n",
    "value.object.generator.displayName AS source, value.object.id AS retweetID\n",
    "MATCH(t:Tweet{tweetID:retweetID}) \n",
    "MERGE (s:Source{source:source}) MERGE (t)-[:USING]->(s)', \n",
    "{batchSize:500}) YIELD * ;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_rt_source_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822d8ac",
   "metadata": {},
   "source": [
    "### Create User node and **\\[User POSTS Tweet\\]** relationship\n",
    "User node contains:  \n",
    "**userID**: id of the user  \n",
    "**userName**: preferred user name of the user.   \n",
    "\"preferredUsername\" is used in order to ensure it is as same as the name referred by others when mentioning him or her in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c36c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_user_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.actor.id AS userID, \n",
    "value.actor.preferredUsername AS userName, value.id AS tweetID\n",
    "MATCH(t:Tweet{tweetID:tweetID}) \n",
    "MERGE (u:User{userID:userID, userName:userName}) \n",
    "MERGE (u)-[:POSTS]->(t)', \n",
    "{batchSize:500}) YIELD * ;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfee59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_user_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d644d7",
   "metadata": {},
   "source": [
    "### Create User node and **\\[User POSTS Tweet**\\] relationship for *Retweeted Tweets*\n",
    "Extract the users for the original retweeted tweets.  \n",
    "*Note: Retweeted tweets data is stored in \"object\", therefore, it is created separately to establish the relationship for retweeted tweets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6177db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rt_user_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.object AS o,\n",
    "value.object.id AS retweetID\n",
    "MATCH(t:Tweet{tweetID:retweetID})\n",
    "FOREACH(a IN o.actor | \n",
    "MERGE (u:User{userID:a.id, userName:a.preferredUsername})\n",
    "MERGE (u)-[:POSTS]->(t))', \n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e999e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_rt_user_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec209898",
   "metadata": {},
   "source": [
    "### Create Hashtag node and **\\[Tweet TAGS Hashtag**\\] relationship\n",
    "Hashtag Node contains:  \n",
    "**tag**: tag(s) used in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hashtag_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.twitter_entities AS e, \n",
    "value.id AS tweetID\n",
    "MATCH(t:Tweet{tweetID:tweetID}) \n",
    "FOREACH (h IN e.hashtags |\n",
    "MERGE (tag:Hashtag {tag:TOLOWER(h.text)})\n",
    "MERGE (tag)<-[:TAGS]-(t))', \n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_hashtag_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79f5f9",
   "metadata": {},
   "source": [
    "### Create Hashtag node and **\\[Tweet TAGS Hashtag**\\] relationship for *Retweeted Tweets*\n",
    "*Note: Retweeted tweets data is stored in \"object\", therefore, it is created separately to establish the relationship for retweeted tweets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rt_hashtag_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.object.twitter_entities AS e,\n",
    "value.object.id AS retweetID\n",
    "MATCH(t:Tweet{tweetID:retweetID})\n",
    "FOREACH (h IN e.hashtags |\n",
    "MERGE (tag:Hashtag {tag:TOLOWER(h.text)})\n",
    "MERGE (tag)<-[:TAGS]-(t))', \n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_rt_hashtag_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f300cba",
   "metadata": {},
   "source": [
    "## The below is addressing Q4 of Part 3 Query. \n",
    "It is presented here as to create the complete graph data model as shown at the beginning of Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb9472",
   "metadata": {},
   "source": [
    "### Create **\\[Tweet MENTIONS User**\\] relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee029f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mentions_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.twitter_entities AS e, \n",
    "value.id AS tweetID\n",
    "MATCH(t:Tweet{tweetID:tweetID}) \n",
    "FOREACH (m IN e.user_mentions |\n",
    "MERGE (mentioned:User {userID:m.id, userName:m.screen_name})\n",
    "MERGE (mentioned)<-[:MENTIONS]-(t))', \n",
    "{batchSize:500}) YIELD * ;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_mentions_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7c531",
   "metadata": {},
   "source": [
    "### Create **\\[Tweet MENTIONS User**\\] relationship for *Retweeted Tweets*\n",
    "*Note: Retweeted tweets data is stored in \"object\", therefore, it is created separately to establish the relationship for retweeted tweets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rt_mentions_query = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.object.twitter_entities AS e, \n",
    "value.object.id AS retweetID\n",
    "MATCH(t:Tweet{tweetID:retweetID}) \n",
    "FOREACH (m IN e.user_mentions |\n",
    "MERGE (mentioned:User {userID:m.id, userName:m.screen_name})\n",
    "MERGE (mentioned)<-[:MENTIONS]-(t))', \n",
    "{batchSize:500}) YIELD * ; \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_rt_mentions_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66802bd9",
   "metadata": {},
   "source": [
    "### Create **\\[User FOLLOWS User**\\] relationship\n",
    "Since we have already included all retweeted tweet in the Tweet node and created all relationship for retweeted tweet, we are able to create FOLLOWS relationship in one go. Assigned weight = 1 to every FOLLOWS relationship. The weight is to be used in addressing Q5 of Part 3 Query.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c199fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_follows_query = '''\n",
    "MATCH (u1:User)-[:POSTS]->(t:Tweet)-[:MENTIONS]->(u2:User)\n",
    "MERGE (u1)-[:FOLLOWS {weight: 1}]->(u2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.query(create_follows_query, db='Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3868f",
   "metadata": {},
   "source": [
    "# Task 3: Query\n",
    "Write Cypher statements in Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569acc0",
   "metadata": {},
   "source": [
    "#### 1. Find the top five most used sources (app or site) to post or share a tweet. For each source return the source name and the number of tweets sent via that source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (t:Tweet)-[:USING]->(s:Source)\n",
    "WITH collect(t) AS tweets, s\n",
    "RETURN s.source AS `Source Name`, size(tweets) AS `Number of Tweets` ORDER BY size(tweets) DESC LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4703bcd",
   "metadata": {},
   "source": [
    "Since Tweet node contains both tweets and retweeted tweets, the above cypher statement will return the top five most popular sources used in all tweets and retweeted tweets. For instance, User1 use Facebook to share tweet1 which is a retweet of tweet2 posted by User2 using TweetDeck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1be138",
   "metadata": {},
   "source": [
    "| Source Name         | Number of Tweets |\n",
    "|---------------------|------------------|\n",
    "| Twitter for iPhone  | 4343             |\n",
    "| Twitter Web Client  | 2805             |\n",
    "| Twitter for Android | 1761             |\n",
    "| TweetDeck           | 913              |\n",
    "| Twitter for iPad    | 467              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b35ee",
   "metadata": {},
   "source": [
    "#### 2. Find the top five most used hashtags across all tweets on each day between 26th and 31st March 2016 (inclusive). For each day, return the date and a list of the five top hashtags in order of popularity on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (h:Hashtag)<-[r1:TAGS]-(t:Tweet)-[:RETWEETS]->(rt:Tweet)\n",
    "WITH t, rt.datePublished AS Date, collect(t) AS tweets, collect(h.tag) AS tags \n",
    "WHERE Date > date(\"2016-03-25\") AND Date < date(\"2016-04-01\") \n",
    "UNWIND tags AS tag \n",
    "WITH Date AS Date, tag AS tag, size(tweets) AS num\n",
    "ORDER BY num DESC\n",
    "RETURN Date AS Date, collect(tag)[..5] AS Tags ORDER BY Date "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907a93d",
   "metadata": {},
   "source": [
    "| Date       | Tags                                                         |\n",
    "|:-----------|:-------------------------------------------------------------|\n",
    "| 2016-03-26 | [\"brands\", \"socialmedia\", \"timemanagement\", \"auspol\", \"nswpol\"]          |\n",
    "| 2016-03-27 | [\"isis\", \"brusselsattacks\", \"brussels\", \"islam\", \"pjnet\"]                |\n",
    "| 2016-03-28 | [\"fighthunger\", \"walmart\", \"ctustrike\", \"lfc\", \"vibewithus\"]             |\n",
    "| 2016-03-29 | [\"model\", \"suicidegirls\", \"suicide_girls\", \"tattoo\", \"tattoos\"]          |\n",
    "| 2016-03-30 | [\"australia\", \"ntaustralia\", \"darwin\", \"tourismtopend\", \"territorylife\"] |\n",
    "| 2016-03-31 | [\"aprilfools\", \"happyfoolday\", \"world\", \"foolsday\", \"april\"]             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef776e",
   "metadata": {},
   "source": [
    "#### 3. Find all users that use any of the same hashtags as user \"m_mrezamm\". This query must exclude any retweets since these posts would automatically contain common tags. The query must return the user name and the number of hashtags that were used in their tweets that are also used by \"m_mrezamm\". Order results by the number of hashtags used in common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bcc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (m:User)-[:POSTS]->(mt:Tweet)-[:TAGS]->(mh:Hashtag)\n",
    "WHERE m.userName = 'm_mrezamm'\n",
    "WITH collect(DISTINCT mh.tag) as commonTags\n",
    "MATCH (u:User)-[:POSTS]->(t:Tweet)-[:TAGS]->(h:Hashtag)\n",
    "WHERE t.action = 'post' AND h.tag in commonTags AND NOT u.userName = 'm_mrezamm'\n",
    "UNWIND commonTags as ctags\n",
    "WITH ctags, h, u, t\n",
    "WHERE h.tag = ctags\n",
    "RETURN DISTINCT u.userName AS `User Name`, collect(h.tag) AS Tags, count(h.tag) AS `Count` ORDER BY `Count` DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2019e6",
   "metadata": {},
   "source": [
    "To exclude any retweets, the action:\"post\" is used to filter away any shared tweets, so that only original tweets are included in the result. The above cypher statement also return the tags used by the users to see which tags they used were the same as the tags used by m_mrezamm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29881e83",
   "metadata": {},
   "source": [
    "| User Name       | Tags                                                | Count |\n",
    "|:----------------|:----------------------------------------------------|-------|\n",
    "| paydaran        | [\"iran\", \"humanrights\", \"unhcr\", \"no2rouhani\", \"eupol\", \"canada\"] | 6     |\n",
    "| boghche         | [\"iran\", \"iran\", \"paris\"]                                   | 3     |\n",
    "| parnian2013     | [\"iran\", \"rohani\", \"autriche\"]                              | 3     |\n",
    "| bhardost        | [\"iran\", \"iran\"]                                          | 2     |\n",
    "| Mojahedineng    | [\"iran\"]                                                | 1     |\n",
    "| CSDHI           | [\"iran\"]                                                | 1     |\n",
    "| Darvish_Roghani | [\"iran\"]                                                | 1     |\n",
    "| YahooBHRP       | [\"humanrights\"]                                         | 1     |\n",
    "| hropenebook     | [\"humanrights\"]                                         | 1     |\n",
    "| syndicalisms    | [\"paris\"]                                               | 1     |\n",
    "| RavenHUWolf     | [\"paris\"]                                               | 1     |\n",
    "| behroozsalam   | [\"paris\"]                                               | 1     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961182ab",
   "metadata": {},
   "source": [
    "#### 4. The original dataset does not contain information about which users follow each other. For this exercise we will infer that any user that MENTIONS another user in a tweet FOLLOWS that user. Write a Cypher expression which creates FOLLOW relationships based on this assumption, for example if UserA mentions UserB in a tweet, then it is assumed that UserA FOLLOWS UserB. Each FOLLOWS relationship added to the graph should also have a ‘weight’ property with a value of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b8463",
   "metadata": {},
   "source": [
    "It was created in part 2. The below are recap of the codes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454b836",
   "metadata": {},
   "source": [
    "\n",
    "[From Part 2] 12. Create **\\[Tweet MENTIONS User\\]** relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7df599",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.twitter_entities AS e, \n",
    "value.id AS tweetID\n",
    "MATCH(t:Tweet{tweetID:tweetID}) \n",
    "FOREACH (m IN e.user_mentions |\n",
    "MERGE (mentioned:User {userID:m.id, screen_name:m.screen_name})\n",
    "MERGE (mentioned)<-[:MENTIONS]-(t))', \n",
    "{batchSize:500}) YIELD * ; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943b94f",
   "metadata": {},
   "source": [
    "[From Part 2] 13. Create **\\[Tweet MENTIONS User\\]** relationship for Retweeted Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ccd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL apoc.periodic.iterate(\n",
    "'CALL apoc.load.json(\"file:///cleaned_10000_tweets.json\") YIELD value', \n",
    "'WITH value.object.twitter_entities AS e, \n",
    "value.object.id AS retweetID\n",
    "MATCH(t:Tweet{tweetID:retweetID}) \n",
    "FOREACH (m IN e.user_mentions |\n",
    "MERGE (mentioned:User {userID:m.id, screen_name:m.screen_name})\n",
    "MERGE (mentioned)<-[:MENTIONS]-(t))', \n",
    "{batchSize:500}) YIELD * ; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94cec65",
   "metadata": {},
   "source": [
    "[From Part 2] 14. Create **\\[User FOLLOWS User\\]** relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ea9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (u1:User)-[:POSTS]->(t:Tweet)-[:MENTIONS]->(u2:User)\n",
    "MERGE (u1)-[:FOLLOWS {weight: 1}]->(u2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9d529",
   "metadata": {},
   "source": [
    "#### 5. Using the FOLLOWS relationship derived in Problem 4, use the Neo4j Graph Data Science library to calculate the most popular nodes using Degree Centrality from the FOLLOWS subgraph. Then, find the top five users with the highest Degree Centrality score. (consider using NATURAL orientation and the weight property for the graph projection). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ed248",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL gds.graph.project(\n",
    " 'myGraph',\n",
    " 'User',\n",
    " {\n",
    " FOLLOWS: {\n",
    " orientation: 'NATURAL',\n",
    " properties: ['weight']\n",
    " }\n",
    " }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL gds.degree.stream('myGraph')\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).userName AS Name, score AS Followers\n",
    "ORDER BY Followers DESC, Name DESC LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc57a5",
   "metadata": {},
   "source": [
    "| Name            | Followers |\n",
    "|-----------------|-----------|\n",
    "| BlakeGeoff      | 35.0      |\n",
    "| ejlazar         | 34.0      |\n",
    "| Twittblaster    | 33.0      |\n",
    "| SamanthaAppley4 | 27.0      |\n",
    "| AlexiaVass      | 27.0      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808140d",
   "metadata": {},
   "source": [
    "# YouTube Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d8e48",
   "metadata": {},
   "source": [
    "https://youtu.be/l6o3g9QMA-o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
